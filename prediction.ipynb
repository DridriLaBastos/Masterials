{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "prediction.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efaZ2tsGBt0c"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUXYuA1KBt0u"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkh0VDKiBt0x"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.data import Dataset\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from keras import Input\n",
        "from keras import Model\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import losses\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import timeseries_dataset_from_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh5BJWiTBt0z"
      },
      "source": [
        "## Test whether Notebook is running on Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1jsBk4HBt00"
      },
      "source": [
        "csvPath = ''\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "  csvPath = 'https://github.com/DridriLaBastos/Masterials/raw/main/PatientsHTA.zip'\n",
        "else:\n",
        "  csvPath = 'PatientsHTA.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_PZ5gvfBt00"
      },
      "source": [
        "dateColumnNames = [\n",
        "    'contact_date',\n",
        "    'Glycemie_der_date',\n",
        "    'HbA1c_der_date',\n",
        "    'der_date_poids',\n",
        "    'der_date_taille',\n",
        "    'first_contact_date'\n",
        "]\n",
        "\n",
        "df = pd.read_csv(csvPath,engine='c',parse_dates=dateColumnNames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1H_O4iABt02"
      },
      "source": [
        "# Suppression des lignes trop peu nombreuses\n",
        "\n",
        "Nous souhaitons faire un apprentissage en utilisant la dimension temporelle comme filtre pour le CNN. Pour ça il faut donc que nous ayons plusieurs entrées. Avant de commencer à traîter les données, nous supprimons toutes les personnes qui n'ont pas rendu visite assez souvent à leur médecin. Ainsi, par le biais de ```person_id```, nous avons choisi arbitrairement que pour être utile à l'apprentissage, il faut au moins 3 visites par patients, soient toutes les lignes dont le ```person_id```est contenu plus de 3 fois dans tout le jeu de données."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvG-6qVABt04"
      },
      "source": [
        "VISIT_NUMBER = 4\n",
        "valueCounts = df.person_id.value_counts()\n",
        "dfEnought = df[df.person_id.isin(valueCounts[valueCounts.values >= VISIT_NUMBER].index)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6-dtaEZBt05"
      },
      "source": [
        "# Suppression des colonnes innutiles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXurQoWcBt05"
      },
      "source": [
        "## Suppression de la colonne ```age_now```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMQLvlvwBt1C"
      },
      "source": [
        "Nous pouvons supprimer la colonne ```age_now``` car les données qu'elle contient sont identiques à celles de la colonne ```year_of_birth```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ_ecbTgBt1F"
      },
      "source": [
        "dfWithoutAgeNow = dfEnought.drop('Age_now', axis='columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVZw6fu5Bt1G"
      },
      "source": [
        "## Suppression de la colonne ```contact_id```\n",
        "\n",
        "En effet, la colonne ```contact_id``` ne représente aucun intérêt pour l'apprentissage car elle ne contient aucun information à même d'influer sur la prédiction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIhnr6Q8Bt1I"
      },
      "source": [
        "dfWithoutContactID = dfWithoutAgeNow.drop('contact_id',axis='columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWGOZTSLBt1K"
      },
      "source": [
        "## Suppression des noms de médicaments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bloGqpJsBt1L",
        "outputId": "4b41948b-0163-483e-bcb2-524c08b8ee8a"
      },
      "source": [
        "dfGroupedByMoleculeLabel = dfWithoutContactID.groupby('product_atc_code')[['molecule_label','short_name','long_name','Classe','product_atc']].count()\n",
        "dfGroupedByMoleculeLabel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTvsCsr8Bt1R"
      },
      "source": [
        "Nous voyons qu'il existe différentes colonnes dont le but est de désigner le médicament prescrit lors de la visite, or nous n'avons besoin que d'une seule colonne garder cette information. De ce fait, nous avons choisi de garder ```product_atc_code```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "pFu6UZLDBt1T",
        "outputId": "ac36356c-8976-490e-d010-fbc06ccf1031"
      },
      "source": [
        "dropColumnNames = dfGroupedByMoleculeLabel.columns.to_list()\n",
        "dfWithATCCode = dfWithoutContactID.drop(dropColumnNames, axis='columns')\n",
        "dfWithATCCode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OunT7DyBt1U"
      },
      "source": [
        "## Suppression des colonnes ```'*der*'```\n",
        "\n",
        "Les colonnes ```'*der*'``` contiennent la dernière donnée. Cette donnée peut être récupérée grâce à la date de la visite et aux valeurs mesurées. Par exemple, il n'est pas nécessaire d'avoir une colonne ```der_date``` ou ```der_mesure```. Les données de ces deux types de colonnes peuvent être récupérées grâce à la ligne qui correspond à la dernière date de la mesure, que nous pouvons trouver grâce à la colonne ```contact_date```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOeBfkOXBt1Z"
      },
      "source": [
        "derColumnNames = []\n",
        "\n",
        "for c in dfWithATCCode.columns:\n",
        "    if ('der_date' in c) or ('der_mesure' in c):\n",
        "        derColumnNames.append(c)\n",
        "\n",
        "dfWithoutDer = dfWithATCCode.drop(derColumnNames,axis='columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMkds8B1Bt1Z"
      },
      "source": [
        "## Suppression des colonnes ```Taille``` et ```Poids```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5poB10WBt1b",
        "outputId": "cc27a00f-e30c-41b5-dca8-a2e896d38cb9"
      },
      "source": [
        "print(f\"Taille: {dfWithoutDer.Taille.isnull().sum()}/{len(dfWithoutDer.Taille)} valeurs nulles (={dfWithoutDer.Taille.isnull().sum()/len(dfWithoutDer.Taille)*100:.2f}%)\")\n",
        "\n",
        "print(f\"Poids: {dfWithoutDer.Poids.isnull().sum()}/{len(dfWithoutDer.Poids)} valeurs nulles (={dfWithoutDer.Poids.isnull().sum()/len(dfWithoutDer.Poids)*100:.2f}%)\".format())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQPIhvbZBt1e"
      },
      "source": [
        "Nous voyons qu'il y a beaucoup trop de valeur nulles. Ces deux colonnes semblent donc difficilement exploitable. Nous pouvons cependant vérifier si pour les patients toutes les valeurs sont à nulles ou s'il n'existe que quelques entrées à nulle par patient mais qu'il y en a beaucoup. Dans ce cas nous pourrions enlever les lignes contenant des valeurs nulles, ou trouver un moyen d'attribuer une valeur à la place de Nan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3Ubb3pwBt1e"
      },
      "source": [
        "dfPersonIdIndex = dfWithoutDer.set_index('person_id',drop=True).sort_index()\n",
        "dfTPGroupBy = dfPersonIdIndex.groupby('person_id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0O4-WeQBt1i",
        "outputId": "31a85d52-a728-4968-85d1-64540279e641"
      },
      "source": [
        "maybeUseful = 0\n",
        "valeurNulle = 0\n",
        "for i,_ in dfTPGroupBy:\n",
        "    if dfPersonIdIndex.loc[i].Taille.isnull().sum() > 0:\n",
        "        valeurNulle += 1\n",
        "        if dfPersonIdIndex.loc[i].Taille.isnull().sum() < len(dfPersonIdIndex.loc[i].Taille):\n",
        "            maybeUseful += 1\n",
        "\n",
        "print(f\"Taille: {maybeUseful} / {valeurNulle} utilisables\")\n",
        "\n",
        "maybeUseful = 0\n",
        "valeurNulle = 0\n",
        "c = 0\n",
        "for i,_ in dfTPGroupBy:\n",
        "    if dfPersonIdIndex.loc[i].Poids.isnull().sum() > 0:\n",
        "        valeurNulle += 1\n",
        "        if dfPersonIdIndex.loc[i].Poids.isnull().sum() < len(dfPersonIdIndex.loc[i].Poids):\n",
        "            maybeUseful += 1\n",
        "\n",
        "print(f\"Poids: {maybeUseful} / {valeurNulle} utilisables\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U8N89ChBt1j",
        "outputId": "b6f1ffad-f052-4a40-af7e-ac4677dc88c3"
      },
      "source": [
        "tailleNan = 0\n",
        "poidsNan = 0\n",
        "oneOfBoth = 0\n",
        "bothNan = 0\n",
        "totalEntries = 0\n",
        "for i,_ in dfTPGroupBy:\n",
        "    totalEntries += 1\n",
        "    hasTailleNan = False\n",
        "    hasPoidsNan = False\n",
        "    if dfPersonIdIndex.loc[i].Taille.isnull().sum() != 0:\n",
        "        tailleNan += 1\n",
        "        hasTailleNan = True\n",
        "    if dfPersonIdIndex.loc[i].Poids.isnull().sum() != 0:\n",
        "        poidsNan += 1\n",
        "        hasPoidsNan = True\n",
        "    if hasTailleNan or hasPoidsNan:\n",
        "        oneOfBoth += 1\n",
        "    if hasTailleNan and hasPoidsNan:\n",
        "        bothNan += 1\n",
        "print(\" --- Statistique par Utilisateur --- \")\n",
        "print(f\"{tailleNan} / {totalEntries} ({tailleNan/totalEntries*100:.2f}%) des utilisateurs ont une valeur nulle pour la taille\")\n",
        "print(f\"{poidsNan} / {totalEntries} ({poidsNan/totalEntries*100:.2f}%) des utilisateurs ont une valeur nulle pour le poids\")\n",
        "print(f\"{oneOfBoth} / {totalEntries} ({oneOfBoth/totalEntries*100:.2f}%) des utilisateurs ont une valeur nulle pour la taille ou le poids\")\n",
        "print(f\"{bothNan} / {totalEntries} ({bothNan/totalEntries*100:.2f}%) des utilisateurs ont les deux valeurs nulle pour la taille ou le poids\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5CF4sP4Bt1k"
      },
      "source": [
        "Nous concluons de l'analyse de ces données que soit toutes les valeurs de poids et de tailles sont entrées, soit aucunes. Cela rend ces informations innexploitables et nous supprimons donc les colonnes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBEk7h-fBt1k"
      },
      "source": [
        "dfWithoutPT = dfWithoutDer.drop(['Taille', 'Poids'],axis='columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQsluJOxBt1l"
      },
      "source": [
        "## Suppressions diverses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMN5ip8jBt1r"
      },
      "source": [
        "Enfin, certaines colonnes n'apportent pas d'informations nécessaires pour la prédiction, nous choisissons de toutes les supprimer ici"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLPjLEKmBt1s",
        "outputId": "36aa2ef9-c17a-4a77-9281-5840d634a3a4"
      },
      "source": [
        "dfWithoutPT.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o2HV0vqBt1t"
      },
      "source": [
        "Les colonnes restantes avec des valeurs ```Nan``` ne nous intéresse pas, nous pouvons les supprimer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Goh72Y-PBt1v"
      },
      "source": [
        "nullAmount = dfWithoutPT.isnull().sum()\n",
        "\n",
        "columnNameToDrop = nullAmount[nullAmount.values > 0].index\n",
        "dfFinal = dfWithoutPT.drop(columnNameToDrop,axis='columns').drop(['cip','dosage_1','dose_1','dose_2','specialty_label','gender_code'],axis='columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF4hIDAOBt1w"
      },
      "source": [
        "# Traîtement des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYWq5P6RBt1w"
      },
      "source": [
        "## Conversion des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EH8JMyWBt1x"
      },
      "source": [
        "### Ajout du temps entre chaque visite (ce que l'on veut prédire)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKXnZphKBt1z"
      },
      "source": [
        "Nous créons d'abord la colonne ```wait_time``` pour qu'elle ait le type de donnée ```deltatime```. nous itèrerons plus tard sur chaque valeur de cette colonne pour lui enlever la valeur précédante pour chaque utilisateur, et ainsi avoir l'intervalle de temps entre chaque visite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "ZfzpABVKBt11"
      },
      "source": [
        "wait_time = dfFinal.contact_date - dfFinal.first_contact_date\n",
        "dfWithTime = dfFinal.drop('first_contact_date',axis='columns')\n",
        "dfWithTime['wait_time'] = wait_time\n",
        "dfWithTime['contactDateYear'] = dfWithTime.contact_date.dt.year\n",
        "dfWithTime['contactDateMonth'] = dfWithTime.contact_date.dt.month\n",
        "dfWithTime['contactDateDayOfYear'] = dfWithTime.contact_date.dt.dayofyear"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "R3atHvmPBt13",
        "outputId": "0ad00041-877d-4f36-e6a4-e2df6cc2c7d0"
      },
      "source": [
        "dfWithTime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3jL_58lBt14"
      },
      "source": [
        "### Encodage des valeurs non numériques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8hn_E4KBt15"
      },
      "source": [
        "#specialtyEncoder = LabelEncoder()\n",
        "ATCEncoder = LabelEncoder()\n",
        "#genderEncoder = LabelEncoder()\n",
        "#dfWithTime.specialty_label = specialtyEncoder.fit_transform(dfWithTime.specialty_label)\n",
        "dfWithTime.product_atc_code = ATCEncoder.fit_transform(dfWithTime.product_atc_code)\n",
        "#dfWithTime.gender_code = genderEncoder.fit_transform(dfWithTime.gender_code)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "pFqWHYlKBt15",
        "outputId": "c0304830-0090-4eed-d22b-a9f768315d9d"
      },
      "source": [
        "dfWithTime.hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vTDeultBt18"
      },
      "source": [
        "### Conversion en ```TimeSeries```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNSctfnIBt2M"
      },
      "source": [
        "Nous définissons simplement le nouvel index comme la colonne donnant l'intervalle de temps entre chaque visite."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "l-sfO2RZBt2N",
        "outputId": "93371f6d-ee96-42a8-d372-81090937f6c3"
      },
      "source": [
        "ts = dfWithTime.set_index(['person_id','contact_date']).sort_index()\n",
        "ts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RwhcepIBt2P"
      },
      "source": [
        "### Attribution des bonnes valeurs de ```time_wait```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl_F60Q4Bt2Q",
        "outputId": "3cd096a6-e2dc-4d72-e99c-375e2f1e85e3"
      },
      "source": [
        "tsWithTime = ts.copy()\n",
        "for i,_ in ts.groupby('person_id'):\n",
        "    len_ = len(ts.loc[i])\n",
        "    tsWithTime.loc[i].wait_time[1:len_] = pd.Series(ts.loc[i].wait_time.to_numpy()[1:len_] - ts.loc[i].wait_time.to_numpy()[:len_-1])\n",
        "    tsWithTime.loc[i].wait_time[0] = pd.Timedelta(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mm-y9aPBt2Q",
        "outputId": "2e240d4e-4174-450a-d803-252a1fa77088"
      },
      "source": [
        "tsWithTimeNumber = tsWithTime.copy()\n",
        "tsWithTimeNumber.wait_time = tsWithTime.wait_time.dt.days\n",
        "tsWithTimeNumber['wait_time_days'] = tsWithTime.wait_time.dt.days\n",
        "tsWithTimeNumber['wait_time_weeks'] = (tsWithTime.wait_time.dt.days / 7).astype(int)\n",
        "tsWithTimeNumber.wait_time.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI5n1JdkBt2R",
        "outputId": "0a38545e-10df-4775-f7c1-05b654d6e5e0"
      },
      "source": [
        "tsWithGoodTime = tsWithTimeNumber[tsWithTimeNumber.wait_time.values <= 300]\n",
        "tsWithGoodTime.wait_time.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVPV96Q4Bt2S"
      },
      "source": [
        "### Transformation de ```wait_time``` en valeur numérique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "oVBztqi1Bt2S",
        "outputId": "456eeae6-447b-4d03-a921-9fcb93958fc4"
      },
      "source": [
        "tsWithTimeMonth = tsWithGoodTime.copy()\n",
        "tsWithTimeMonth.wait_time = (tsWithGoodTime.wait_time / 30).astype(int)\n",
        "tsWithTimeMonth.wait_time[tsWithTimeMonth.wait_time >= 4] = 4\n",
        "tsWithTimeMonth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCRtoAoKBt2S",
        "outputId": "8be35d78-24fa-44ec-925d-c5291d51801c"
      },
      "source": [
        "tsResetIndex = tsWithTimeMonth.copy()\n",
        "tsResetIndex = tsResetIndex.reset_index()\n",
        "print( tsResetIndex )\n",
        "tsValueCounts = tsResetIndex.person_id.value_counts()\n",
        "tsIndexed = tsResetIndex[tsResetIndex.person_id.isin(tsValueCounts[tsValueCounts.values >= VISIT_NUMBER].index)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRvgwfR_Bt2T"
      },
      "source": [
        "atcCodeValues = tsWithTimeMonth.product_atc_code\n",
        "waitTimeValues = tsWithTimeMonth.wait_time\n",
        "\n",
        "tsFinal = pd.concat([tsWithTimeMonth,pd.get_dummies(atcCodeValues),pd.get_dummies(waitTimeValues)],axis='columns').drop(['product_atc_code','wait_time'],axis='columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWKL9H2sBt2T"
      },
      "source": [
        "# Prédiction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQR1Tee5Bt2U"
      },
      "source": [
        "## Création des données d'entraînement/test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "sSISD_NrBt2W"
      },
      "source": [
        "#yColumnNames = ['product_atc_code', 'wait_time']\n",
        "\n",
        "#xList,yList = [],[]\n",
        "#for i,_ in tsWithTimeMonth.groupby('person_id'):\n",
        "    # Mme ZERHAOUI a dit qu'il fallait transposer, je transpose\n",
        "    # Pour l'instant je retourne au model évident : une série temporel qui contient 4 éléments de n_features données, on verra après pour la trasposition\n",
        "#    currentSeriesX = tsFinal.loc[i]\n",
        "#    currentSeriesY = tsWithTimeMonth.loc[i]\n",
        "#    for j in range(0,len(currentSeriesX)-VISIT_NUMBER+1):\n",
        "#        xList.append(currentSeriesX[j:j+VISIT_NUMBER-1].to_numpy().astype('float32'))\n",
        "        #xList.append(currentSeries.to_numpy().astype('float32'))\n",
        "#        yList.append(currentSeriesY[yColumnNames].values[j+VISIT_NUMBER-1].astype('float32'))\n",
        "        #yList.append(currentSeries[yColumnNames].astype('float32'))\n",
        "\n",
        "#xData = np.array(xList).reshape((len(xList),xList[0].shape[0],xList[0].shape[1]))\n",
        "#yData = np.array(yList).reshape((len(yList),len(yColumnNames)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(tsWithTimeMonth.groupby('person_id'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tsFinal.loc[291.0][:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "VISIT_THRESHOLD = VISIT_NUMBER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8z92Yl_Bt2W"
      },
      "source": [
        "yColumnNames = ['product_atc_code', 'wait_time']\n",
        "xList,yList = [],[]\n",
        "for i,_ in tsWithTimeMonth.groupby('person_id'):\n",
        "    if(len(tsFinal.loc[i]) >= VISIT_THRESHOLD):\n",
        "        xList.append(tsFinal.loc[i][:VISIT_THRESHOLD][:-1].to_numpy().astype('float32'))\n",
        "        yList.append(tsWithTimeMonth[yColumnNames].loc[i][:VISIT_THRESHOLD][-1:].to_numpy().astype('float32'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6jmr4NbBt2W"
      },
      "source": [
        "xData = np.array(xList)\n",
        "yData = np.array(yList)\n",
        "\n",
        "xs = xData.shape\n",
        "ys = yData.shape\n",
        "\n",
        "xData = xData.reshape(xs[0],1,xs[1],xs[2])\n",
        "yData = yData.reshape(ys[0],ys[1],ys[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnz7WaiwBt2X"
      },
      "source": [
        "print(f\"{xData.shape} --- {yData.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvADOzYqBt2c"
      },
      "source": [
        "l = len(xData) // 2\n",
        "xData1, yData1 = xData[:l], yData[:l]\n",
        "xData2, yData2 = xData[:-l], yData[:-l]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51B0QmjyBt2c"
      },
      "source": [
        "trainUse1 = int(len(xData1) * 2 / 3)\n",
        "testUse1 = len(xData1) - trainUse1\n",
        "\n",
        "xTrain1, xTest1, yTrain1, yTest1 = xData1[:trainUse1],xData1[-testUse1:],yData1[:trainUse1],yData1[-testUse1:]\n",
        "\n",
        "print(f\"Train: {xTrain1.shape} --- Test: {xTest1.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix469jhvBt2d"
      },
      "source": [
        "#Cellule pour faire des tests et comprendre la syntaxe que j'ai utilisée après\n",
        "L = [[1,2,3,4,5,6],[7,8,9],[10,11]]\n",
        "for l in L:\n",
        "    # -2: permet d'avoir les deux derniers\n",
        "    # :le-2 permet d'avoir toutes les entrées sauf les deux dernières\n",
        "    print(f\"{l[-2:]} | {l[:-2]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIsM9mCiBt2g"
      },
      "source": [
        "print(xData2.shape, \"   \", yData2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jp4B1gGBt2k"
      },
      "source": [
        "xTrain2, yTrain2 = xData2, yData2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tsFinal.loc[452710.0][VISIT_THRESHOLD:VISIT_THRESHOLD*2][:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "xList2, yList2 = [],[]\n",
        "for i,_ in tsWithTimeMonth.groupby('person_id'):\n",
        "    if(len(tsFinal.loc[i]) >= VISIT_THRESHOLD*2):\n",
        "        xList2.append(tsFinal.loc[i][VISIT_THRESHOLD:VISIT_THRESHOLD*2][:-1].to_numpy().astype('float32'))\n",
        "        yList2.append(tsWithTimeMonth[yColumnNames].loc[i][VISIT_THRESHOLD:VISIT_THRESHOLD*2][-1:].to_numpy().astype('float32'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xTest2 = np.array(xList2)\n",
        "yTest2 = np.array(yList2)\n",
        "\n",
        "xs2 = xTest2.shape\n",
        "ys2 = yTest2.shape\n",
        "\n",
        "xTest2 = xTest2.reshape(xs2[0],1,xs2[1],xs2[2])\n",
        "yTest2 = yTest2.reshape(ys2[0],ys2[1],ys2[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEGSOnZbBt24"
      },
      "source": [
        "## Création du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocscm0g3Bt26"
      },
      "source": [
        "ATC_CODE = 0\n",
        "WAIT_TIME = 1\n",
        "toTrain = WAIT_TIME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_YQ1aemBt29"
      },
      "source": [
        "#model = models.Sequential()\n",
        "#model.add(layers.Conv1D(filters=256,kernel_size=VISIT_NUMBER-1, activation=None, input_shape=xData.shape[-3:]))\n",
        "#model.add(layers.Attention())\n",
        "#model.add(layers.Dense(units=32,activation='relu'))\n",
        "#model.add(layers.LeakyReLU())\n",
        "#model.add(layers.GaussianDropout(0.05))\n",
        "#model.add(layers.Conv1D(filters=128,kernel_size=VISIT_NUMBER-1, padding=\"same\", activation=None))\n",
        "#model.add(layers.LeakyReLU())\n",
        "#model.add(layers.GaussianDropout(0.05))\n",
        "#model.add(layers.Conv1D(filters=128,kernel_size=VISIT_NUMBER-1, padding=\"same\", activation=None))\n",
        "#model.add(layers.LeakyReLU())\n",
        "#model.add(layers.GaussianDropout(0.05))\n",
        "#model.add(layers.Conv1D(filters=128,kernel_size=VISIT_NUMBER-1, padding=\"same\", activation=None))\n",
        "#model.add(layers.LeakyReLU())\n",
        "#model.add(layers.GaussianDropout(0.05))\n",
        "#model.add(layers.GlobalMaxPooling2D())\n",
        "#if toTrain == ATC_CODE:\n",
        "#    model.add(layers.Dense(units=len(ATCEncoder.classes_),activation='softmax'))\n",
        "#elif toTrain == WAIT_TIME:\n",
        "#    model.add(layers.Dense(units=tsWithTimeMonth.wait_time.max()+1,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = Input(shape=xData.shape[-3:])\n",
        "x = layers.Conv1D(filters=256,kernel_size=VISIT_NUMBER-1, activation=None)(inputs)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv1D(filters=256,kernel_size=VISIT_NUMBER-1, activation=None)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv1D(filters=256,kernel_size=VISIT_NUMBER-1, activation=None)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.GlobalMaxPooling2D()(x)\n",
        "atcOutputs = layers.Dense(units=len(ATCEncoder.classes_),activation='softmax',name='outputATC')(x)\n",
        "waitTimeOutputs = layers.Dense(units=tsWithTimeMonth.wait_time.max()+1,activation='softmax',name='outputWaitTime')(x)\n",
        "model = Model(inputs=inputs,outputs=[atcOutputs,waitTimeOutputs],name=\"NiceCNN\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LCBSaWfBt2-"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxslPST3Bt2-"
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['sparse_categorical_accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "yTrain = {\n",
        "    'outputATC' : yTrain1[:,:,ATC_CODE],\n",
        "    'outputWaitTime' : yTrain1[:,:,WAIT_TIME]\n",
        "}\n",
        "\n",
        "yTest = {\n",
        "    'outputATC' : yTest1[:,:,ATC_CODE],\n",
        "    'outputWaitTime' : yTest1[:,:,WAIT_TIME]   \n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR-MAv4VBt2_",
        "tags": [
          "outputPrepend"
        ]
      },
      "source": [
        "history = model.fit(xTrain1,yTrain,epochs=300,validation_data=(xTest1,yTest))\n",
        "#history = model.fit(xTrain2,yTrain2,epochs=100,validation_data=(xTest2,yTest2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scZ6D7ahBt3A"
      },
      "source": [
        "loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
        "val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
        "acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
        "val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
        "\n",
        "## As loss always exists\n",
        "epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
        "\n",
        "fig, (p1,p2) = plt.subplots(1,2,figsize=(13,4))\n",
        "\n",
        "## Loss\n",
        "for l in loss_list:\n",
        "    p1.plot(epochs, history.history[l], 'b', label='Training loss')\n",
        "for l in val_loss_list:\n",
        "    p1.plot(epochs, history.history[l], 'g', label='Validation loss')\n",
        "\n",
        "p1.set(xlabel='Epochs',ylabel='Loss')\n",
        "\n",
        "## Accuracy\n",
        "for l in acc_list:\n",
        "    p2.plot(epochs, history.history[l], 'b', label='Training accuracy')\n",
        "for l in val_acc_list:    \n",
        "    p2.plot(epochs, history.history[l], 'g', label='Validation accuracy')\n",
        "\n",
        "p1.set(xlabel='Epochs',ylabel='Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-JwcemBBt3B"
      },
      "source": [
        "yTest = yTest1\n",
        "predictions = np.argmax(model.predict(xTest1),axis=1).reshape(yTest[:,:,toTrain].shape)\n",
        "print(f\"Précision '{yColumnNames[toTrain]}': {(predictions == yTest[:,:,toTrain]).sum()/len(yTest)*100:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-J2c9KJBt3E"
      },
      "source": [
        "SLICE_START = 200\n",
        "SLICE_SIZE = 50\n",
        "SLICE_END = SLICE_START + SLICE_SIZE\n",
        "\n",
        "plt.plot(yTest[SLICE_START:SLICE_END,:,toTrain],label='expected')\n",
        "plt.plot(predictions[SLICE_START:SLICE_END,0],color='r',label='predicted')\n",
        "\n",
        "fig.legend()\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jMCOmdoBt3F"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}